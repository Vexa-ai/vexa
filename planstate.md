# VEXA Speaker Identification Implementation Plan

## Current Status: ‚úÖ PHASE 3 COMPLETED SUCCESSFULLY 

### ‚úÖ **Phase 1: COMPLETED** - Basic Speaker Detection & WebSocket Communication

**Implementation Date:** January 2025  
**Status:** ‚úÖ **FULLY WORKING** - All tests passed successfully

#### What Was Implemented:
1. **‚úÖ Speaker Detection Integration** - Integrated validated speaker detection logic from `speakers_console_test.js` into Vexa Bot's `page.evaluate()` block
2. **‚úÖ WebSocket Control Messages** - Added JSON message handling for speaker events and session control 
3. **‚úÖ Session Start Events** - Implemented session start event publishing to Redis stream
4. **‚úÖ Speaker Event Transmission** - Real-time speaker activity events sent to WhisperLive
5. **‚úÖ LEAVING_MEETING Signal** - Graceful session termination handling

#### Test Results (January 2025):
**‚úÖ All Critical Tests PASSED:**
- **Speaker Detection**: Real-time detection of `SPEAKER_START`/`SPEAKER_END` events for multiple participants
- **WebSocket Communication**: Fixed bytes/string handling - no more protocol errors
- **Transcription Flow**: Successful real-time transcription ("321123", "–≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ", etc.)
- **Multi-language Support**: Automatic language detection (Russian/English) working
- **Redis Integration**: Session start events and transcription data flowing to Redis streams
- **Session Management**: Proper session UID tracking and lifecycle management
- **Error Handling**: Robust message type handling with proper fallbacks

#### Technical Achievements:
- **Fixed Critical Bug**: Resolved WhisperLive bytes/string compatibility issue
- **Message Protocol**: Successfully handles both binary audio and JSON control messages  
- **Performance**: Real-time processing with minimal latency
- **Reliability**: Self-monitoring and health checks working correctly
- **Scalability**: Redis stream architecture ready for multi-session handling

---

### ‚úÖ **Phase 2: COMPLETED** - WhisperLive Server-Side Event Reception & Redis Forwarding

**Implementation Date:** June 2025  
**Status:** ‚úÖ **FULLY WORKING** - Speaker events successfully forwarded to Redis

#### What Was Implemented:
1. **‚úÖ WebSocket Message Handling** - Added support for `speaker_activity` and `session_control` message types
2. **‚úÖ Redis Stream Publishing** - Speaker events published to Redis streams for processing
3. **‚úÖ Session End Handling** - Graceful session termination and cleanup
4. **‚úÖ Timestamp Preservation** - Client timestamps correctly forwarded with server metadata

#### Test Results (June 2025):
**‚úÖ All Integration Tests PASSED:**
- **Message Reception**: WhisperLive correctly receives speaker_activity messages from bot
- **Redis Publishing**: Events successfully published to transcription_segments stream  
- **Error Handling**: Robust handling of malformed messages and connection issues
- **Performance**: Real-time event processing with minimal latency

---

### ‚úÖ **Phase 3: COMPLETED** - Transcription Collector Data Ingestion & Persistence

**Implementation Date:** June 2025  
**Status:** ‚úÖ **FULLY WORKING** - Speaker events successfully stored in database

#### What Was Implemented:
1. **‚úÖ Speaker Activity Processing** - Added `speaker_activity` message type handling
2. **‚úÖ Database Schema Updates** - Fixed `client_timestamp_ms` column from INTEGER to BIGINT
3. **‚úÖ Speaker Events Storage** - Real-time storage of speaker events in PostgreSQL
4. **‚úÖ Session Correlation** - Speaker events linked to meeting sessions and participants

#### Test Results (June 2025):
**‚úÖ All Database Tests PASSED:**
- **Message Processing**: Successfully processes `speaker_activity` messages from Redis
- **Database Storage**: **285 speaker events** successfully stored in `speaker_events` table
- **Schema Fix**: Resolved INTEGER overflow issue with Unix timestamps (changed to BIGINT)
- **Real-time Processing**: Events stored within seconds of detection
- **Data Integrity**: Proper foreign key relationships and indexing working

#### Database Evidence:
```sql
-- Sample stored speaker events (latest 5)
ID  | Participant    | Event Type    | Timestamp (ms)  | Server Time
285 | info vexa      | SPEAKER_END   | 1748973120353   | 2025-06-03 17:52:00
284 | devices        | SPEAKER_END   | 1748973120353   | 2025-06-03 17:52:00  
283 | info vexa      | SPEAKER_START | 1748973117338   | 2025-06-03 17:51:57
282 | devices        | SPEAKER_START | 1748973117338   | 2025-06-03 17:51:57
281 | info vexa      | SPEAKER_END   | 1748973113653   | 2025-06-03 17:51:53
```

#### üö® **Known Issue Identified:**
**"devices" Speaker Misinterpretation**: The speaker detection logic is incorrectly identifying a "devices" participant in every other row. This appears to be the bot misinterpreting UI elements, device indicators, or system elements as speakers.

**Impact**: Approximately 50% of speaker events are false positives for "devices"
**Priority**: High - needs investigation and filtering logic
**Location**: Likely in Vexa Bot's speaker detection JavaScript or CSS class monitoring

---

### üöÄ **Phase 4: IN PROGRESS** - Core Mapping Logic & Final Storage

**Target Start:** Immediate  
**Status:** üü° **READY TO START** - Prerequisites completed

#### Scope:
1. **Fix "devices" Speaker Detection** - Filter out false positive speaker events
2. **Transcription-Speaker Correlation** - Map transcription segments to actual speakers
3. **Timeline Reconstruction** - Build accurate speaker timeline from events
4. **Speaker Transition Handling** - Manage overlapping speech and speaker changes
5. **Advanced Timeline API** - Provide speaker-aware transcription endpoints

#### Prerequisites Met:
- ‚úÖ 285+ speaker events being stored successfully
- ‚úÖ Database schema ready for mapping logic
- ‚úÖ Real-time event processing pipeline working
- ‚úÖ Session management and correlation working

#### Next Actions:
1. **IMMEDIATE**: Investigate and fix "devices" speaker misdetection in Vexa Bot
2. **SHORT-TERM**: Implement speaker event filtering/validation logic
3. **MEDIUM-TERM**: Develop transcription-to-speaker mapping algorithms
4. **LONG-TERM**: Advanced speaker analytics and timeline visualization

---

### üéØ **Success Metrics Achieved:**

#### Phase 1-3 Combined Results:
- **End-to-End Pipeline**: ‚úÖ Bot ‚Üí WhisperLive ‚Üí Redis ‚Üí Collector ‚Üí Database
- **Real-time Processing**: ‚úÖ Speaker events stored within seconds of detection
- **Database Scale**: ‚úÖ 285+ events successfully processed and stored
- **Performance**: ‚úÖ No bottlenecks or processing delays observed
- **Reliability**: ‚úÖ Robust error handling and automatic recovery
- **Data Integrity**: ‚úÖ Proper timestamps, foreign keys, and relationships

#### Ready for Production:
**Phase 1-3 implementation is production-ready for speaker event capture and storage. Phase 4 optimization needed for accurate speaker identification.**

# Vexa Speaker Identification & Transcription Mapping Plan

## I. Vexa Bot (Client-Side - `services/vexa-bot/core/src/platforms/google.ts`)

1.  **Integrate Speaker Detection Logic:**
    *   Adapt the JavaScript code from `speakers_console_test.js` (which has been validated for identifying speaker changes based on DOM class mutations) into the `page.evaluate()` block in `google.ts`.
    *   The script will monitor participant elements for class changes corresponding to `speakingClasses` (e.g., `['Oaajhc', 'HX2H7', 'wEsLMd', 'OgVli']`) and `silenceClass` (e.g., `'gjg47c'`).
    *   Capture:
        *   Event type: `SPEAKER_START` or `SPEAKER_END`.
        *   Participant's display name.
        *   Google Meet's `data-participant-id` (if available, otherwise the script's generated `vexa-id-`).
        *   Client-side timestamp using `Date.now()`.
    *   **Robustness:** The script should ensure that if a participant element is removed from the DOM while they are considered "speaking", a `SPEAKER_END` event is synthesized and dispatched.

2.  **Send Speaker Events via WebSocket to WhisperLive:**
    *   When a speaker event is detected, the browser-side script will construct and send a new JSON message over the existing WebSocket connection.
    *   **New WebSocket Message Format (Client to WhisperLive Server):**
        ```json
        {
          "type": "speaker_activity",
          "payload": {
            "event_type": "SPEAKER_START", // or "SPEAKER_END"
            "participant_name": "John Doe",
            "participant_id_meet": "meet-specific-id-string", // or "vexa-id-xxxx"
            "client_timestamp_ms": 1678886400000, // Result of Date.now()
            // Include existing contextual information already sent with audio config:
            "uid": "websocket-connection-uid",
            "token": "bot-api-token",
            "platform": "google_meet",
            "meeting_id": "native-meeting-id",
            "meeting_url": "https://meet.google.com/xxx-yyy-zzz"
          }
        }
        ```
    *   These messages will be sent in parallel with the ongoing audio data stream.

3.  **Signal Session End:**
    *   When the Vexa Bot is preparing to leave the meeting (e.g., triggered by an API call, or after a configured duration), it **MUST** send a specific message via WebSocket to WhisperLive *before* closing the WebSocket or terminating its browser page.
    *   **New WebSocket Message Format (Client to WhisperLive Server for Session Control):**
        ```json
        {
          "type": "session_control",
          "payload": {
            "event": "LEAVING_MEETING",
            "uid": "websocket-connection-uid", // Critical for identifying the session
            "client_timestamp_ms": 1678886400000, // Result of Date.now()
            "token": "bot-api-token",
            "platform": "google_meet",
            "meeting_id": "native-meeting-id"
          }
        }
        ```

## II. WhisperLive (Server-Side - `services/WhisperLive/whisper_live/server.py`)

1.  **Modify WebSocket Server to Handle New Message Types:**
    *   Update the WebSocket connection handler in `TranscriptionServer` (or its equivalent) to recognize:
        *   Messages where `type == "speaker_activity"` for speaker events.
        *   Messages where `type == "session_control"` for session lifecycle events like `LEAVING_MEETING`.
    *   Parse the `payload` of these messages.

2.  **Publish Speaker Events to a New Redis Stream:**
    *   Utilize the existing `TranscriptionCollectorClient` instance.
    *   Add a new method to `TranscriptionCollectorClient` (e.g., `publish_speaker_event(event_data)`).
    *   This method will publish the processed speaker event to a dedicated Redis stream.
        *   **New Redis Stream Name:** `speaker_events` (configurable via an environment variable like `REDIS_SPEAKER_EVENTS_STREAM_KEY`).
        *   **Redis Message Payload (WhisperLive to Redis Stream `speaker_events`):**
            ```json
            {
              // These fields are directly from the "payload" of the client's message
              "event_type": "SPEAKER_START",
              "participant_name": "John Doe",
              "participant_id_meet": "meet-specific-id-string",
              "client_timestamp_ms": 1678886400000,
              "uid": "websocket-connection-uid",
              "token": "bot-api-token",
              "platform": "google_meet",
              "meeting_id": "native-meeting-id",
              "meeting_url": "https://meet.google.com/xxx-yyy-zzz",
              // Additional server-side metadata
              "server_timestamp_iso": "2023-03-15T12:00:00.123Z" // ISO 8601 timestamp when WhisperLive processed this
            }
            ```

3.  **Handle Session End Signaling from Client or Connection Drop:**
    *   If a `session_control` message with `event: "LEAVING_MEETING"` is received from the client:
        *   Use the `client_timestamp_ms` from this message as the primary source for the session end time.
    *   If the WebSocket connection for a specific `uid` is closed/terminated unexpectedly by the client (without a prior `LEAVING_MEETING` message):
        *   Use the server's current time as the session end time.
    *   In either case, WhisperLive will publish a `session_end` event.
    *   This event **MUST** be published to the **`transcription_segments` Redis stream** to ensure it's processed in conjunction with session start and transcription data by the Transcription Collector.
    *   **Redis `session_end` Message Payload (WhisperLive to `transcription_segments` Stream):**
        ```json
        {
          "type": "session_end",
          "uid": "websocket-connection-uid",
          "token": "bot-api-token", // For identifying user context
          "platform": "google_meet",
          "meeting_id": "native-meeting-id",
          "session_end_timestamp_iso": "2023-03-15T13:00:00.000Z" // Authoritative ISO 8601 timestamp of session end
        }
        ```

## III. Transcription Collector (Service - `services/transcription-collector/main.py`)

1.  **Consume from New `speaker_events` Redis Stream:**
    *   Define a new Redis stream name and consumer group name in the configuration (e.g., `REDIS_SPEAKER_EVENTS_STREAM_NAME`, `REDIS_SPEAKER_EVENTS_CONSUMER_GROUP`).
    *   Create a new consumer group for this stream during startup if it doesn't exist.
    *   Implement a new asynchronous background task (e.g., `consume_speaker_events_stream()`), similar to `consume_redis_stream()`, that uses `redis_client.xreadgroup` to read messages from the `speaker_events` stream.
    *   This task will delegate message processing to a new function, e.g., `process_speaker_event_message(message_id, message_data)`.

2.  **Process and Store Speaker Events in PostgreSQL:**
    *   The `process_speaker_event_message()` function will:
        *   Parse the JSON payload from the Redis message.
        *   Perform necessary validations (token, user, meeting).
        *   **Crucially, attempt to find the `MeetingSession` using `uid`, `meeting_id`, `token`. If the `MeetingSession` is not yet found (e.g., because the `session_start` event from the `transcription_segments` stream hasn't been processed yet), the message MUST NOT be acknowledged. Redis will then redeliver it, allowing time for the `MeetingSession` to be created. This prevents orphaned speaker events.**
        *   Once the `MeetingSession` is found and its `id` retrieved, store the speaker event details into the new PostgreSQL table.
    *   **New PostgreSQL Table: `speaker_events_log`** (to be defined in `libs/shared-models/shared_models/models.py`):
        *   `id`: SERIAL PRIMARY KEY
        *   `meeting_session_id`: INTEGER, NOT NULL, REFERENCES `meeting_sessions(id)`
        *   `participant_name`: VARCHAR(255), NOT NULL
        *   `participant_id_meet`: VARCHAR(255), NULL (Google Meet's specific participant ID)
        *   `event_type`: VARCHAR(50), NOT NULL (e.g., "SPEAKER_START", "SPEAKER_END")
        *   `client_timestamp`: TIMESTAMPTZ, NOT NULL (Converted from `client_timestamp_ms`, stored in UTC)
        *   `server_timestamp`: TIMESTAMPTZ, NOT NULL (From `server_timestamp_iso`, stored in UTC)
        *   `raw_event_payload`: JSONB, NULL (For auditing/debugging the full event from Redis)
        *   `created_at`: TIMESTAMPTZ, DEFAULT CURRENT_TIMESTAMP

3.  **Process `session_end` Events (from `transcription_segments` stream):**
    *   In the existing `process_stream_message` function (which handles messages from `transcription_segments`):
        *   Add a new case for `message_type == "session_end"`.
        *   This handler will:
            *   Parse the payload.
            *   Find the corresponding `MeetingSession` using `uid` (and `meeting_id`, `token` for robustness).
            *   If found, update its **new `session_end_utc` column** with the `session_end_timestamp_iso` from the message.
            *   If `session_start_utc` is not set on this session record yet (should be rare), log an error, but still set `session_end_utc`.
    *   **Modify `MeetingSession` Table Schema:** (in `libs/shared-models/shared_models/models.py`)
        *   Add `session_end_utc`: TIMESTAMPTZ, NULL

4.  **Implement Transcription-to-Speaker Mapping Logic:**
    *   This will likely be a new periodic background task or integrated into an existing one that processes finalized transcriptions.
    *   **Timestamp Synchronization Strategy:**
        *   Transcription segments have `start_offset_ms` and `end_offset_ms` relative to the audio stream's start.
        *   The `MeetingSession` table has `session_start_utc`. This timestamp is the absolute anchor.
        *   Speaker events (`SpeakerEventLog.client_timestamp`) are absolute UTC timestamps derived from `client_timestamp_ms`.
        *   To map a transcription segment:
            1.  Calculate its absolute UTC start: `abs_segment_start = meeting_session.session_start_utc + timedelta(milliseconds=transcription.start_offset_ms)` (assuming `session_start_utc` is correctly timezone-aware UTC).
            2.  Calculate its absolute UTC end: `abs_segment_end = meeting_session.session_start_utc + timedelta(milliseconds=transcription.end_offset_ms)`.
    *   **Mapping Algorithm:**
        *   For each `MeetingSession`, fetch its `Transcription` records (that are `speaker_mapping_status = 'PENDING'`) and its `SpeakerEventLog` records, sorted by `client_timestamp`.
        *   For each transcription segment:
            *   Iterate through the speaker events for that session.
            *   Identify which speaker (based on `participant_name` or `participant_id_meet`) was "active" during the `[abs_segment_start, abs_segment_end]` interval.
            *   A speaker is considered active if their most recent `SPEAKER_START` event (before or at `abs_segment_start`) does not have a corresponding `SPEAKER_END` event with `client_timestamp` *before* `abs_segment_end`.
            *   **Handling Missing `SPEAKER_END`:** If a participant has an open `SPEAKER_START` and no subsequent `SPEAKER_END` event within the session's recorded events, their speaking period is considered to extend until:
                1.  The `MeetingSession.session_end_utc` (if set).
                2.  Or, if `session_end_utc` is not set, then until the `client_timestamp` of the latest `SpeakerEventLog` entry for that session, or the end time of the last known transcription segment for that session (whichever is later). This provides a fallback if the explicit session end signal fails.
        *   **Handling Overlaps/Ambiguity:**
            *   **Single Speaker:** If the segment falls entirely within one speaker's active window (no other speakers active during the segment), map it. Update `transcriptions` table with `mapped_speaker_name`, `mapped_participant_id_meet`, and set `speaker_mapping_status = 'MAPPED'`.
            *   **Multiple Speakers:** If the segment overlaps with periods where multiple speakers were simultaneously active (based on their START/END events), mark `speaker_mapping_status = 'MULTIPLE'`.
            *   **No Speaker:** If no speaker was active during the segment's timeframe, mark `speaker_mapping_status = 'UNKNOWN'`.
            *   **Error:** If an error occurs during mapping, set `speaker_mapping_status = 'ERROR'`.
    *   The mapping logic should be batch-oriented.

5.  **Modify `transcriptions` PostgreSQL Table Schema:** (in `libs/shared-models/shared_models/models.py`)
    *   Add new columns:
        *   `mapped_speaker_name`: VARCHAR(255), NULL
        *   `mapped_participant_id_meet`: VARCHAR(255), NULL
        *   `speaker_mapping_status`: VARCHAR(50), NULL, DEFAULT 'PENDING' (Values: "PENDING", "MAPPED", "UNKNOWN", "MULTIPLE", "ERROR")
        *   `mapped_at`: TIMESTAMPTZ, NULL (Timestamp of when the mapping was last attempted/updated)
        *   *(Optional for advanced tracing)* `mapped_speaker_event_log_id_start`: INTEGER, NULL, REFERENCES `speaker_events_log(id)`
        *   *(Optional for advanced tracing)* `mapped_speaker_event_log_id_end`: INTEGER, NULL, REFERENCES `speaker_events_log(id)`

## IV. General Considerations

*   **Configuration Management:** All new stream names, consumer group names, and other parameters should be configurable via environment variables.
*   **Timestamp Precision and Timezones:**
    *   Ensure all timestamps are stored and processed consistently as UTC (e.g., using `TIMESTAMPTZ` in PostgreSQL). Convert JavaScript's `Date.now()` (milliseconds since epoch) to proper datetime objects in UTC.
    *   `client_timestamp_ms` from speaker events and transcription segment offsets (relative to `MeetingSession.session_start_utc`) are the primary sources for temporal alignment in mapping, mitigating minor clock skew between client and server processing times.
*   **Error Handling and Logging:** Implement comprehensive error handling and logging across all modified services for easier debugging and monitoring.
*   **Idempotency:** Design Redis stream consumers and data processing logic to be idempotent where possible, to handle message redeliveries gracefully. Particularly for speaker event storage and session end updates.
*   **Message Ordering:** Using separate Redis streams for primary transcriptions and speaker events is maintained. The mapping logic should fetch relevant data sets (e.g., all speaker events for a session) before processing to account for any minor inter-stream delivery variations.
*   **Scalability:** Consider the potential load on Redis and PostgreSQL, especially with many concurrent meetings.
*   **Participant Identity:** Changes in participant names or `participant_id_meet` (if unstable from the provider) mid-session can pose challenges to uniquely tracking a speaker throughout. The current plan relies on the identifiers as captured. Future enhancements might explore heuristics for merging identities if this becomes a significant issue.
*   **Late Joins:** The system can only map speaker activity observed by the Vexa Bot from the time it successfully joins and initializes in the meeting. Pre-existing speaker activity will not be captured.
*   **Backfilling:** Plan for how existing transcriptions (if any) would be processed or if this feature only applies to new data.
*   **Testing:** Develop a thorough testing strategy, including unit tests for new logic, integration tests for service interactions, and end-to-end tests simulating various scenarios (simultaneous speakers, abrupt disconnects, participant leaves).
*   **Deployment:** Update Dockerfiles, CI/CD pipelines, and any deployment scripts for the changes in each service.

This plan provides a structured approach to implementing speaker identification and mapping within the Vexa ecosystem. 




Okay, I've restructured the plan in planstate.md into a phased approach with minimal, logically separated steps, each concluding with a smoke test. This should make implementation more manageable.
Here's a summary of the phased approach:
Phase 1: Vexa Bot - Client-Side Speaker Event Journey (Detection & Initial Transmission)
Focus: Getting the Vexa Bot to accurately detect SPEAKER_START/SPEAKER_END events in the browser and send these, along with a LEAVING_MEETING signal, to the WhisperLive WebSocket.
Smoke Test: Observe WebSocket messages via browser dev tools or a local proxy to confirm correct payloads are sent for speaker activities and bot departure.
Phase 2: WhisperLive - Server-Side Event Reception & Redis Forwarding
Focus: Modifying WhisperLive to understand the new WebSocket message types (speaker_activity, session_control), publish speaker events to a new speaker_events Redis stream, and publish session_end events to the existing transcription_segments Redis stream.
Smoke Test: Use redis-cli to monitor both Redis streams and verify that WhisperLive correctly forwards the events originating from Vexa Bot.
Phase 3: Transcription Collector - Data Ingestion & Persistence
Focus: Updating the Transcription Collector to consume messages from the new speaker_events Redis stream and the session_end messages from the transcription_segments stream. This involves creating the new speaker_events_log PostgreSQL table, adding session_end_utc to meeting_sessions, and ensuring data is correctly parsed, validated, linked, and stored.
Smoke Test: After running Phases 1 & 2, query PostgreSQL tables (speaker_events_log, meeting_sessions) to confirm speaker events and session end times are accurately persisted and linked. Test deferred ACK for speaker events if their corresponding session isn't immediately found.
Phase 4: Transcription Collector - Core Mapping Logic & Final Storage
Focus: Implementing the algorithm that maps transcriptions to speakers. This involves adding new mapping-related columns to the transcriptions table and creating the logic to correlate transcription segment timestamps with speaker activity periods, handling overlaps and missing SPEAKER_END events.
Smoke Test: With data populated from previous phases, run the mapping task. Query the transcriptions table to verify that mapped_speaker_name, speaker_mapping_status, etc., are correctly updated for various speaking scenarios.
This structure emphasizes separation of concerns and allows for incremental testing.
I will now apply these changes to planstate.md.