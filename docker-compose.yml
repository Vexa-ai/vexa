services:
  api-gateway:
    image: localhost:5000/vexa-api-gateway:latest # ADJUST REGISTRY AND IMAGE NAME AS NEEDED
    ports:
      - "${API_GATEWAY_HOST_PORT:-8056}:8000"
    environment:
      - ADMIN_API_URL=http://admin-api:8001
      - BOT_MANAGER_URL=http://bot-manager:8080
      - TRANSCRIPTION_COLLECTOR_URL=http://transcription-collector:8000
      - LOG_LEVEL=DEBUG
    init: true
    depends_on:
      - admin-api
      - bot-manager
      - transcription-collector
    networks:
      - vexa_default
    deploy:
      replicas: 1

  admin-api:
    # build:
    #   context: .
    #   dockerfile: services/admin-api/Dockerfile
    image: localhost:5000/vexa-admin-api:latest # ADDED IMAGE LINE
    ports:
      - "${ADMIN_API_HOST_PORT:-8057}:8001"
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - LOG_LEVEL=DEBUG
    init: true
    depends_on:
      - redis
      - postgres
    networks:
      - vexa_default
    deploy:
      replicas: 1

  bot-manager:
    image: localhost:5000/vexa-bot-manager:latest # ADJUST REGISTRY AND IMAGE NAME AS NEEDED
    environment:
      - REDIS_URL=redis://redis:6379/0
      - BOT_IMAGE_NAME=localhost:5000/vexa-bot:dev # IMPORTANT: vexa-bot image from your registry
      # This will be the overlay network name created by Swarm.
      # If stack name is 'vexa_stack' and network in YAML is 'vexa_default',
      # the actual network name will be 'vexa_stack_vexa_default'.
      - DOCKER_NETWORK=vexa_stack_vexa_default 
      - LOG_LEVEL=DEBUG
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - DOCKER_HOST=unix://var/run/docker.sock
      - DEVICE_TYPE=${DEVICE_TYPE}
      - WHISPER_LIVE_GPU_URL=ws://whisperlive:9090
      - WHISPER_LIVE_CPU_URL=ws://whisperlive-cpu:9092
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    init: true
    depends_on:
      - redis
      - postgres
    networks:
      - vexa_default
    deploy:
      replicas: 1

  whisperlive:
    # profiles: ["gpu"] # Manage this by deploying/not deploying the service or separate stack files
    # build:
    #   context: .
    #   dockerfile: services/WhisperLive/Dockerfile.project
    image: localhost:5000/vexa-whisperlive-gpu:latest # ADDED IMAGE LINE (ensure this is your GPU variant)
    volumes:
      - ./hub:/root/.cache/huggingface/hub
      - ./services/WhisperLive/models:/app/models
    environment:
      # Use Redis Stream URL instead of WebSocket URL
      - REDIS_STREAM_URL=redis://redis:6379/0/transcription_segments
      # Keep the old URL for backward compatibility
      - TRANSCRIPTION_COLLECTOR_URL=redis://redis:6379/0/transcription_segments
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_STREAM_NAME=transcription_segments
      - LANGUAGE_DETECTION_SEGMENTS=${LANGUAGE_DETECTION_SEGMENTS}
      - VAD_FILTER_THRESHOLD=${VAD_FILTER_THRESHOLD}
      - DEVICE_TYPE=${DEVICE_TYPE}
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        if [ "$${DEVICE_TYPE}" = "cuda" ]; then
          echo 'INFO: DEVICE_TYPE is cuda, starting WhisperLive GPU service.' &&
          exec python3 /app/run_server.py --port 9090 --backend faster_whisper -fw /root/.cache/huggingface/hub/models--Systran--faster-whisper-medium/snapshots/08e178d48790749d25932bbc082711ddcfdfbc4f;
        else
          echo "INFO: DEVICE_TYPE is not cuda (it is '$${DEVICE_TYPE}'), WhisperLive GPU service will not start. Sleeping indefinitely." &&
          sleep infinity;
        fi
    expose:
      - "9090" #use for transcription web socket
      - "9091" #use for health check
    deploy:
      replicas: 1 # Keep 1 for GPU typically
      # placement:
      #   constraints:
      #     - node.labels.gpu == true # Example: Label your GPU node(s) `docker node update --label-add gpu=true <node-name>`
      resources:
        reservations:
          # devices:  # This syntax is problematic for docker stack deploy
          #   - driver: nvidia
          #     capabilities: [gpu]
          generic_resources:
            - discrete_resource_spec:
                kind: "NVIDIA-GPU" # This kind depends on how GPUs are exposed to Swarm. Common for nvidia-docker2.
                value: 1 # Number of GPUs to reserve
      update_config:
        parallelism: 1
        delay: 30s # Allow more time for model loading
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s # Give time for model loading
    init: true
    depends_on:
      - transcription-collector
    networks:
      - vexa_default
      - whispernet
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Add Traefik labels for service discovery
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whisperlive.rule=Host(`whisperlive.localhost`)"
      - "traefik.http.routers.whisperlive.entrypoints=web"
      - "traefik.http.services.whisperlive.loadbalancer.server.port=9090"
      # Special headers for WebSocket support
      - "traefik.http.middlewares.whisperlive-headers.headers.customrequestheaders.Connection=upgrade"
      - "traefik.http.middlewares.whisperlive-headers.headers.customrequestheaders.Upgrade=websocket"
      - "traefik.http.routers.whisperlive.middlewares=whisperlive-headers"

  # CPU version of WhisperLive for users without GPU
  whisperlive-cpu:
    # profiles: ["cpu"] # Manage via separate stack files or service deployment choices
    # build:
    #   context: .
    #   dockerfile: services/WhisperLive/Dockerfile.cpu
    image: localhost:5000/vexa-whisperlive-cpu:latest # ADDED IMAGE LINE (ensure this is your CPU variant)
    volumes:
      - ./hub:/root/.cache/huggingface/hub
      - ./services/WhisperLive/models:/app/models
    environment:
      - REDIS_STREAM_URL=redis://redis:6379/0/transcription_segments
      - TRANSCRIPTION_COLLECTOR_URL=redis://redis:6379/0/transcription_segments
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_STREAM_NAME=transcription_segments
      - LANGUAGE_DETECTION_SEGMENTS=10
      - VAD_FILTER_THRESHOLD=0.5
      - DEVICE_TYPE=${DEVICE_TYPE}
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        if [ "$${DEVICE_TYPE}" = "cpu" ]; then
          echo 'INFO: DEVICE_TYPE is cpu, starting WhisperLive CPU service.' &&
          exec python3 /app/run_server.py --port 9092 --backend faster_whisper -fw /root/.cache/huggingface/hub/models--Systran--faster-whisper-tiny/snapshots/d90ca5fe260221311c53c58e660288d3deb8d356;
        else
          echo "INFO: DEVICE_TYPE is not cpu (it is '$${DEVICE_TYPE}'), WhisperLive CPU service will not start. Sleeping indefinitely." &&
          sleep infinity;
        fi
    expose:
      - "9092" #use for transcription web socket
      - "9093" #use for health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9093/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 60s # Longer start period for CPU model loading
    init: true
    depends_on:
      - transcription-collector
    networks:
      - vexa_default
      - whispernet
    # Don't auto-start CPU version, users can manually start it
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Add Traefik labels for service discovery
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whisperlive-cpu.rule=Host(`whisperlive-cpu.localhost`)"
      - "traefik.http.routers.whisperlive-cpu.entrypoints=web"
      - "traefik.http.services.whisperlive-cpu.loadbalancer.server.port=9092"
      - "traefik.http.middlewares.whisperlive-cpu-headers.headers.customrequestheaders.Connection=upgrade"
      - "traefik.http.middlewares.whisperlive-cpu-headers.headers.customrequestheaders.Upgrade=websocket"
      - "traefik.http.routers.whisperlive-cpu.middlewares=whisperlive-cpu-headers"

  # Replace nginx load-balancer with Traefik
  traefik:
    image: traefik:v2.10
    ports:
      - "${TRAEFIK_WEB_HOST_PORT:-9090}:80" # Expose on host port
      - "${TRAEFIK_DASHBOARD_HOST_PORT:-8085}:8080" # Traefik dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik.toml:/etc/traefik/traefik.toml:ro
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--log.level=DEBUG"
    networks:
      - vexa_default
      - whispernet
    healthcheck:
      test: ["CMD", "wget", "--spider", "--quiet", "http://localhost/ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  transcription-collector:
    # build:
    #   context: .
    #   dockerfile: services/transcription-collector/Dockerfile
    image: localhost:5000/vexa-transcription-collector:latest # ADDED IMAGE LINE
    ports:
      - "${TRANSCRIPTION_COLLECTOR_HOST_PORT:-8123}:8000"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=vexa
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_STREAM_NAME=transcription_segments
      - REDIS_CONSUMER_GROUP=collector_group
      - REDIS_STREAM_READ_COUNT=10
      - REDIS_STREAM_BLOCK_MS=2000
      - BACKGROUND_TASK_INTERVAL=10
      - IMMUTABILITY_THRESHOLD=30
      - REDIS_SEGMENT_TTL=3600
      - REDIS_CLEANUP_THRESHOLD=86400
      - LOG_LEVEL=DEBUG
    init: true
    depends_on:
      - redis
      - postgres
    networks:
      - vexa_default
    restart: unless-stopped

  redis:
    image: redis:7.0-alpine
    command:
      ["redis-server", "--appendonly", "yes", "--appendfsync", "everysec"]
    volumes:
      - redis-data:/data
    networks:
      - vexa_default
    restart: unless-stopped

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=vexa
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d vexa"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - vexa_default
    restart: unless-stopped
    ports:
      - "${POSTGRES_HOST_PORT:-5438}:5432"

volumes:
  redis-data:
  postgres-data:

networks:
  vexa_default:
    driver: overlay
    attachable: true
  whispernet:
    driver: overlay
