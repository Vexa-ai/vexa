---
title: "Vexa Lite Deployment Guide"
description: "Deploy Vexa as a single Docker container with no GPU requirements. Vexa Lite is a stateless container that connects to external database and transcription servi"
---
# Vexa Lite Deployment Guide

Deploy Vexa as a single Docker container with no GPU requirements. Vexa Lite is a stateless container that connects to external database and transcription services.

> ðŸš€ **One-click platform deployments**: For platform-specific deployment guides (Fly.io, Railway, Render, etc.), see the [vexa-lite-deploy repository](https://github.com/Vexa-ai/vexa-lite-deploy).

## Overview

**Why Vexa Lite?**

- **Easy deployment** â€” Single container, no multi-service orchestration required
- **Stateless** â€” All data stored in your database; easy to redeploy and scale
- **No GPU required** â€” Transcription runs outside the container (remote service)
- **Flexible DB** â€” Use a managed Postgres (recommended) or local Postgres for dev

## Deployment Options

As of v0.8, Vexa Lite is designed for **remote transcription**. Choose your database location:

| Database | Transcription | Use Case |
|----------|---------------|----------|
| Remote | Remote | Fastest setup, GPU-free, production-ready |
| Local | Remote | Quick development setup |

---

## Complete Setup Examples

### Example 1: Remote Database + Remote Transcription

**Best for:** Production deployments, fastest setup

**Pros:** `gpu-free` `serverless ready` `managed backups` `production ready` `scalable` 

**Cons:** `external services` `ongoing costs`

**Setup steps:**

1. **Create Supabase database:**
   - Create a new project at [supabase.com](https://supabase.com)
   - On the project page, click **Connect** button
   - Select method: **Session pooler**
   - Copy your connection string (example format):
     ```
     postgresql://postgres.your_project_id:[YOUR-PASSWORD]@aws-1-eu-west-1.pooler.supabase.com:5432/postgres
     ```
   - Replace `[YOUR-PASSWORD]` with your actual database password

2. **Get transcription API key:**

   - Get your API key from your Vexa Cloud dashboard (or your chosen transcription provider)
   - `TRANSCRIBER_URL` = `https://transcription.vexa.ai/v1/audio/transcriptions`

3. **Run Vexa Lite:**
```bash
docker run -d \
  --name vexa \
  -p 8056:8056 \
  -e DATABASE_URL="postgresql://postgres.your_project_id:password@aws-0-us-west-2.pooler.supabase.com:5432/postgres" \
  -e DB_SSL_MODE="require" \
  -e ADMIN_API_TOKEN="your-admin-token" \
  -e TRANSCRIBER_URL="https://transcription.vexa.ai/v1/audio/transcriptions" \
  -e TRANSCRIBER_API_KEY="your-api-key" \
  vexaai/vexa-lite:latest
```

---

### Example 2: Local Database + Remote Transcription

**Best for:** Development, quick testing

**Pros:** `gpu free` `fast start`  `dev friendly` `lower cost`

**Cons:** `no managed backups` `external transcription` `local db management`

**Setup steps:**

1. **Create network:**
```bash
docker network create vexa-network
```

2. **Start PostgreSQL:**
```bash
docker run -d \
  --name vexa-postgres \
  --network vexa-network \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=vexa \
  -p 5432:5432 \
  postgres:latest
```

3. **Get transcription API key:**
   - Get your API key from your Vexa Cloud dashboard (or your chosen transcription provider)
   - `TRANSCRIBER_URL` = `https://transcription.vexa.ai/v1/audio/transcriptions`

4. **Run Vexa Lite:**
```bash
docker run -d \
  --name vexa \
  --network vexa-network \
  -p 8056:8056 \
  -e DATABASE_URL="postgresql://postgres:your_password@vexa-postgres:5432/vexa" \
  -e ADMIN_API_TOKEN="your-admin-token" \
  -e TRANSCRIBER_URL="https://transcription.vexa.ai/v1/audio/transcriptions" \
  -e TRANSCRIBER_API_KEY="your-api-key" \
  vexaai/vexa-lite:latest
```

**Note:** Vexa container must use `--network vexa-network` to connect to local PostgreSQL.

---

## Environment Variables Reference

| Variable | Required | Description | Example |
|----------|----------|-------------|---------|
| `DATABASE_URL` | Yes | PostgreSQL connection string | `postgresql://user:pass@host:5432/vexa` |
| `ADMIN_API_TOKEN` | Yes | Secret token for admin operations | `your-secret-admin-token` |
| `TRANSCRIBER_URL` | Yes | Transcription service endpoint | `https://transcription.example.com/v1/audio/transcriptions` |
| `TRANSCRIBER_API_KEY` | Yes | API key for transcription service | `your-api-key` |
| `STORAGE_BACKEND` | Optional | Recording storage backend: `local`, `minio`, or `s3` | `s3` |
| `LOCAL_STORAGE_DIR` | Optional | Local recordings directory (when `STORAGE_BACKEND=local`) | `/var/lib/vexa/recordings` |
| `DB_SSL_MODE` | Optional | SSL mode for database connection | `require` (for Supabase) |

---

## Recording Storage (Recordings + Playback)

Vexa Lite can store recording artifacts and expose them via the recordings API (for example, for post-meeting playback in a UI).

Recommended (stateless deployments):

- Use object storage and keep the VM/container stateless:
  - `STORAGE_BACKEND=s3` (AWS S3 or S3-compatible providers)
  - Set the required S3 environment variables (`AWS_REGION`, `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `S3_BUCKET`, and optional `S3_ENDPOINT`/`S3_SECURE` for non-AWS providers)

Local filesystem (testing only):

- If you use `STORAGE_BACKEND=local`, you must mount a volume at `LOCAL_STORAGE_DIR` or recordings will be lost when the container is replaced:

```bash
docker run -d \
  --name vexa \
  -p 8056:8056 \
  -v vexa-recordings:/var/lib/vexa/recordings \
  -e STORAGE_BACKEND=local \
  -e LOCAL_STORAGE_DIR=/var/lib/vexa/recordings \
  -e DATABASE_URL="postgresql://user:pass@host/vexa" \
  -e ADMIN_API_TOKEN="your-admin-token" \
  -e TRANSCRIBER_URL="https://transcription.service" \
  -e TRANSCRIBER_API_KEY="transcriber-token" \
  vexaai/vexa-lite:latest
```

For the full storage matrix (Docker Compose / Lite / Kubernetes) and playback endpoint behavior, see [`docs/recording-storage.md`](recording-storage.md).

## Next Steps

- Test the deployment: Follow `nbs/0_basic_test.ipynb`

## Platform-Specific Deployments

For one-click deployment configurations on specific platforms (Fly.io, Railway, Render, Google Cloud Run, AWS, etc.), see the **[vexa-lite-deploy repository](https://github.com/Vexa-ai/vexa-lite-deploy)**. It provides:
- Platform-specific configuration files
- Step-by-step deployment guides
- Environment variable templates
- Troubleshooting tips for each platform
